{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0WViBS4E7yh1"
   },
   "source": [
    "# Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1iZkq3j9PWJ"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color, filters\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "snzl_-7u9kBA"
   },
   "outputs": [],
   "source": [
    "# Dataset images directory\n",
    "DATASET_IMAGES_PATH = '../dataset-images'\n",
    "\n",
    "# Grid-based dataset csv file\n",
    "DATASET_CSV_PATH = '../dataset-numpy/grid_dataset_8.csv'\n",
    "\n",
    "# Scaler location\n",
    "SCALER_PATH = '../classifiers/scaler.joblib'\n",
    "\n",
    "# KNN Classifier location\n",
    "KNN_CLASSIFIER_PATH = '../classifiers/knn_classifier.joblib'\n",
    "\n",
    "# The Grid Size used in the dataset\n",
    "GRID_SIZE = 8\n",
    "\n",
    "# Temp directory\n",
    "TEMP_DIR_PATH = '../temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJQxTLQ4tf6E"
   },
   "source": [
    "# Helper Functions\n",
    "These functions are all used in the feature extraction state, for more information on their use and how they work, please consult its documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEE0ujZYtfjs"
   },
   "outputs": [],
   "source": [
    "# Crop an image (size 128x32) into four images (size 32x32)\n",
    "# Returns an array of four cropped images\n",
    "def crop_image(image):\n",
    "  crops = []\n",
    "  for i in range(5):\n",
    "    y1 = 0\n",
    "    y2 = 32\n",
    "    x1 = i * 32\n",
    "    x2 = (i + 1) * 32\n",
    "    crops.append(image[y1:y2, x1:x2])\n",
    "  \n",
    "  return crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QeU0SAeGthyV"
   },
   "outputs": [],
   "source": [
    "# Transform an image to its binary form\n",
    "def to_binary(image):\n",
    "  grey = color.rgb2gray(image)\n",
    "  thresh = filters.threshold_isodata(grey)\n",
    "  return grey < thresh\n",
    "\n",
    "# Get grid based features\n",
    "def to_grid(binary):\n",
    "  grids = []\n",
    "  lg = int(len(binary) / GRID_SIZE)\n",
    "\n",
    "  for row in range(0, GRID_SIZE):\n",
    "    row_of_grids = []\n",
    "    for col in range(0, GRID_SIZE):\n",
    "      grid = []\n",
    "      for y in range(lg*row, lg*row + lg):\n",
    "        for x in range (lg*col, lg*col + lg):\n",
    "          grid.append(binary[y][x])\n",
    "      row_of_grids.append(grid)\n",
    "    grids.append(row_of_grids)\n",
    "  \n",
    "  return grids\n",
    "\n",
    "# Count all positive values in the grid\n",
    "def count_positive(grid):\n",
    "  count = []\n",
    "\n",
    "  for y in range(0, len(grid)):\n",
    "    for x in range(0, len(grid[y])):\n",
    "      sum = np.sum(grid[y][x])\n",
    "      count.append(sum)\n",
    "  \n",
    "  return count\n",
    "\n",
    "# Transform an image into an array of sums of positive\n",
    "# values in the grids\n",
    "def image_to_count(image):\n",
    "  binary = to_binary(image)\n",
    "  grid = to_grid(binary)\n",
    "  positive_count = count_positive(grid)\n",
    "  return positive_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GnJ-aDthWGXC"
   },
   "source": [
    "# Grid Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnO-DdfDrQTd"
   },
   "source": [
    "As no huge improvement over the obtained dataset(s) could be found during our feature analysis, we will train the model with one of the better performing datasets we generated during the feature extraction stage.\n",
    "\n",
    "We'll be training the model using the features from an 8x8 grid, as these got us the best results with the least amount of data (64 values instead of 256 or 1024 for the bigger grids). We won't be optimizing the data by removing columns, as this yielded no (significant) improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8166,
     "status": "ok",
     "timestamp": 1586511820255,
     "user": {
      "displayName": "Jasper Sijgers",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMV5mgyq6OiBFr7_IG1qHskr3VehldL5sVO79W=s64",
      "userId": "09274429075529465880"
     },
     "user_tz": -120
    },
    "id": "HGRsNkwHCXjK",
    "outputId": "9fe9d781-1d00-4b30-cf50-7947ecae161c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the dataset into a DataFrame\n",
    "df_grid = pd.read_csv(DATASET_CSV_PATH)\n",
    "\n",
    "# Describe the dataset to see if it's been loaded in properly\n",
    "df_grid.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqtFAYi3CROE"
   },
   "source": [
    "## KNN Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOI8P9Surzbu"
   },
   "source": [
    "We can create a KNN model by removing the labels from our dataframe, scaling our data using a MinMaxScaler and spliting it up into train and test sets. The KNN Classifier will be trained on the train set, which consists of 90% of our total dataset. It will then be tested (scored) using the remaining 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8353,
     "status": "ok",
     "timestamp": 1586511820452,
     "user": {
      "displayName": "Jasper Sijgers",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMV5mgyq6OiBFr7_IG1qHskr3VehldL5sVO79W=s64",
      "userId": "09274429075529465880"
     },
     "user_tz": -120
    },
    "id": "0igoQj1ZC6F4",
    "outputId": "f361eb0e-e94b-4518-f22d-31ca835ce55d"
   },
   "outputs": [],
   "source": [
    "# Get the dataset without the labels from the DataFrame\n",
    "X = df_grid.drop('label', axis=1)\n",
    "\n",
    "# Get an array of labels that correspond with the dataset above\n",
    "Y = df_grid['label']\n",
    "\n",
    "# Create a MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the dataset and scale the data\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create train and test sets (for both data and labels), with 90% of the data\n",
    "# being used to train and 10% to test the model\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=.1)\n",
    "\n",
    "# Create a KNN Classifier with K = 3\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier on the training set\n",
    "knn_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Score the classifier using the built in score function and the test set\n",
    "# created earlier\n",
    "score = knn_classifier.score(X_test, Y_test)\n",
    "percentage = round( score * 100 , 2)\n",
    "\n",
    "# Print the received score as a percentage\n",
    "print('score: {}%'.format(percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7etltInPsOSr"
   },
   "source": [
    "We can export our model (and MinMaxScaler) using the joblib library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8347,
     "status": "ok",
     "timestamp": 1586511820453,
     "user": {
      "displayName": "Jasper Sijgers",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMV5mgyq6OiBFr7_IG1qHskr3VehldL5sVO79W=s64",
      "userId": "09274429075529465880"
     },
     "user_tz": -120
    },
    "id": "8llxZnS4D1TC",
    "outputId": "269409b6-94f6-4b1d-b3d4-5a8c16cad708"
   },
   "outputs": [],
   "source": [
    "# Export the MinMaxScaler\n",
    "dump(scaler, SCALER_PATH)\n",
    "\n",
    "# Export the Model\n",
    "dump(knn_classifier, KNN_CLASSIFIER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-4tdr4Ga_OD"
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqvyRMaMcdz9"
   },
   "source": [
    "Using the K-Fold Cross Validation, one can (accurately) determine if a model is actually accurate or just overfit. This is done by splitting up the dataset into K parts (in this case 10), of which one is used for testing and the rest for training. \n",
    "\n",
    "The cross_val_score trains the KNN model ten times, each of which a different group (out of the ten) is used for testing. This means that a different test set is used every time and that the test set is 10% of the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8991,
     "status": "ok",
     "timestamp": 1586511821104,
     "user": {
      "displayName": "Jasper Sijgers",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMV5mgyq6OiBFr7_IG1qHskr3VehldL5sVO79W=s64",
      "userId": "09274429075529465880"
     },
     "user_tz": -120
    },
    "id": "4TfS5BMUbBM5",
    "outputId": "048c932a-1e65-4eca-d0b5-98dfb8e19ff4"
   },
   "outputs": [],
   "source": [
    "# Create a new KNN Classifier for cross validation with K = 3\n",
    "knn_cv = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train model with a cross validation value of 10\n",
    "cv_scores = cross_val_score(knn_cv, X_scaled, Y, cv=10)\n",
    "\n",
    "# Calculate the average score\n",
    "avg = cv_scores.sum() / 10\n",
    "percentage = round(avg * 100, 2)\n",
    "print('average score: {0}%'.format(percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "crTVQA3tEjlP"
   },
   "source": [
    "## Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_e4usuiEqi6"
   },
   "outputs": [],
   "source": [
    "# Load the preprocessor\n",
    "preproc = load(SCALER_PATH) \n",
    "\n",
    "# Load your final classifier\n",
    "clf = load(KNN_CLASSIFIER_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fa9VKRgoEz0Y"
   },
   "outputs": [],
   "source": [
    "  \"\"\"\n",
    "  Load an image from file and predict the four digits in the image.\n",
    "  The result should be an array containing the 4 digits (as string)\n",
    "  \"\"\"\n",
    "def classify_image(filename):\n",
    "    result = list()\n",
    "        \n",
    "    # Load the image from file\n",
    "    img_array = io.imread(filename)\n",
    "    crops = crop_image(img_array)\n",
    "\n",
    "    # For each digit, collect features, preprocess and predict\n",
    "    for i in range(4):\n",
    "      image_crop = crops[i]\n",
    "\n",
    "      X = image_to_count(image_crop)\n",
    "      X_scaled = preproc.transform([X])\n",
    "\n",
    "      Y = clf.predict(X_scaled)\n",
    "      result.append(str(Y[0]))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13766,
     "status": "ok",
     "timestamp": 1586511825898,
     "user": {
      "displayName": "Jasper Sijgers",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMV5mgyq6OiBFr7_IG1qHskr3VehldL5sVO79W=s64",
      "userId": "09274429075529465880"
     },
     "user_tz": -120
    },
    "id": "7eimxsMHE-3v",
    "outputId": "aad31fa3-8666-4ff7-ac3d-edf8e54a9359"
   },
   "outputs": [],
   "source": [
    "# Outcomes\n",
    "correct_classified_digits = 0\n",
    "incorrect_classified_digits = 0\n",
    "correct_classified_zipcodes = 0\n",
    "incorrect_classified_zipcodes = 0\n",
    "\n",
    "# Score the classifier\n",
    "files = glob.glob(os.path.join(DATASET_IMAGES_PATH, '*.png'))\n",
    "for f in files:\n",
    "    # Get the correct label from the filename\n",
    "    correct_label = f[-8:-4]\n",
    "    # Predict using the classifier\n",
    "    predicted_label = classify_image(f)\n",
    "    \n",
    "    # Score digits\n",
    "    zipcode_correct = True\n",
    "    for i in range(len(correct_label)):\n",
    "        if str(correct_label[i]) == str(predicted_label[i]):\n",
    "            correct_classified_digits += 1\n",
    "        else:\n",
    "            incorrect_classified_digits += 1\n",
    "            zipcode_correct = False\n",
    "    \n",
    "    # Score correct zipcodes\n",
    "    if zipcode_correct:\n",
    "        correct_classified_zipcodes += 1\n",
    "    else:\n",
    "        incorrect_classified_zipcodes += 1\n",
    "\n",
    "print(\"Digit accuracy: \", (correct_classified_digits / (correct_classified_digits + incorrect_classified_digits)), \"(\", correct_classified_digits, \"/\", incorrect_classified_digits, \")\")\n",
    "print(\"Zipcode accuracy: \", (correct_classified_zipcodes / (correct_classified_zipcodes + incorrect_classified_zipcodes)), \"(\", correct_classified_zipcodes, \"/\", incorrect_classified_zipcodes, \")\")        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOWndr8HHxNc"
   },
   "source": [
    "Observed accuracies:\n",
    "\n",
    "\n",
    "| Grid size:                      | 1x1 | 2x2 | 4x4 |\n",
    "|---------------------------------|-----|-----|-----|\n",
    "| Digit Accuracy / Zipcode Accuracy | 0.15677083333333333 / 0.0 | 0.734375 / 0.3104166666666667 | 0.9770833333333333 / 0.9166666666666666 |\n",
    "| Digit Accuracy / Zipcode Accuracy | 0.16458333333333333 / 0.0 | 0.728125 / 0.28541666666666665 | 0.9755208333333333 / 0.9104166666666667 |\n",
    "| Digit Accuracy / Zipcode Accuracy | 0.1640625 / 0.0020833333333333333 | 0.7338541666666667 / 0.3125 | 0.9765625 / 0.9125 |\n",
    "| AVERAGE / AVERAGE | 16.18% / 0.00% | 73.21% / 30.28% | 97.64% / 91.32% |\n",
    "\n",
    "| Grid size: | 8x8 | 16x16 | 32x32 |\n",
    "|-----|-----|-----|-----|\n",
    "| Digit Accuracy / Zipcode Accuracy | 0.9880208333333333 / 0.9520833333333333 | 0.9890625 / 0.95625 | 0.9822916666666667 / 0.9291666666666667 |\n",
    "| Digit Accuracy / Zipcode Accuracy | 0.9895833333333334 / 0.9583333333333334 | 0.9869791666666666 / 0.9479166666666666 | 0.9848958333333333 / 0.9395833333333333 |\n",
    "| Digit Accuracy / Zipcode Accuracy | 0.9895833333333334 / 0.9583333333333334 | 0.9869791666666666 / 0.95 | 0.9838541666666667 / 0.9354166666666667 |\n",
    "| AVERAGE / AVERAGE | 98.91% / 95.63% | 98.77% / 95.14% | 98.37% / 93.47% |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSUcullJ1O3t"
   },
   "source": [
    "# Image based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pdtDaunS4ec6"
   },
   "source": [
    "Author: Dovydas Valiulis 436254"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vS7N87dq7T4k"
   },
   "source": [
    "Finally, we trained our classifiers to see what scores we can get. During this phase we looked at five classifiers:\n",
    "1. KNeighborsClassifier (n nearest neighbors)\n",
    "2. GaussianNB (gaussian naive bias)\n",
    "3. SVC (Support Vector Machines)\n",
    "4. DecisionTreeClassifier\n",
    "5. RandomForestClassifier\n",
    "\n",
    "Also, we fitted two more classifiers. First, we fitted AdaBoostClassifier using our best fit classifier out of the first five to see if we can improve results and then we fitted QuadraticDiscriminantAnalysis to see what score could it reach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvRV0_5h2Gax"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Maf_h8V27WKw"
   },
   "source": [
    "Before any of that, we loaded our data that was made in the previous phases. First, we loaded labels because they are the same for all datasets. Then we have 3 different datasets. \n",
    "1.  Manually selected feature dataset\n",
    "2. Automatically selected feature dataset using chi2 algorithm\n",
    "3. Automatically selected feature dataset using the f-classif algorithm\n",
    "\n",
    "We provide results of each dataset in future sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vs0PjNyn2FJp"
   },
   "outputs": [],
   "source": [
    "# loading labels of the data set\n",
    "labels = load(TEMP_DIR_PATH + '/datasets/label-dataset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wT832c5R7-WN"
   },
   "source": [
    "**To load the dataset execute one of the following three code cells.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMlZbBfc7Xng"
   },
   "source": [
    "Load manual feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aRcayHVe2FIR"
   },
   "outputs": [],
   "source": [
    "# Loading data from manualy selected features\n",
    "X = load(TEMP_DIR_PATH + '/datasets/manualy-selected-feature-dataset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNAQkplm7ZHs"
   },
   "source": [
    "Load auto features (chi2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1pyHtS-2FCf"
   },
   "outputs": [],
   "source": [
    "# Loading data from automatically selected features\n",
    "X = load(TEMP_DIR_PATH + '/datasets/auto-selected-features-chi2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BU8ZNUKA7ZeE"
   },
   "source": [
    "Load auto features (f-classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EILnn7xt2E-A"
   },
   "outputs": [],
   "source": [
    "# Loading data from automatically selected features\n",
    "X = load(TEMP_DIR_PATH + '/datasets/auto-selected-features-f-classif.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRrTzg3w2QuE"
   },
   "source": [
    "## Split data into train and validation sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cH3KH3FO8fdh"
   },
   "source": [
    "To avoid overfitting our classifiers we decided to split our data into training and validation datasets. The training dataset is 90% of the whole dataset and the validation dataset is 10%. to assure that our training and validation datasets are always the same we specify random_state seed as 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3iLWI-XB2E7j"
   },
   "outputs": [],
   "source": [
    "# Spliting data and labels into validation and training sets\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X, labels, test_size=0.10, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P5GryHo82aMc"
   },
   "source": [
    "## Train\n",
    "To find the best hyperparameters for a specific classifier we are using the GridSearchCV module from sklearn. As already mentioned we tested five classification algorithms with each dataset and gathered their score for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kDG9Hcni2eax"
   },
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFSr7Kb32E5U"
   },
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors': range(1,10), \\\n",
    "            'weights': ['uniform', 'distance'], \\\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \\\n",
    "            'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']}\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "gs_clf = GridSearchCV(clf, parameters, cv=5, iid=False)\n",
    "gs_clf.fit(X_train, y_train)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qwWvdf14Cp_"
   },
   "source": [
    "**GridSearchCV Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYucV-IV3uul"
   },
   "source": [
    "| Dataset         | n_neighbors | weights | algorithm | metric  | score |\n",
    "|-----------------|-------------|---------|-----------|---------|-------|\n",
    "| Manual          |     5       |distance |  auto     |euclidean| 88.41%|\n",
    "| Auto chi2       |     5       |distance |  auto     |euclidean| 88.41%|\n",
    "| Auto f-classif  |     5       |distance |  auto     |euclidean| 88.41%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Um-gLlBk2jVr"
   },
   "source": [
    "### Gaussian naive bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DwRiV3tJ2E1p"
   },
   "outputs": [],
   "source": [
    "parameters = {}\n",
    "\n",
    "clf = GaussianNB()\n",
    "gs_clf = GridSearchCV(clf, parameters, cv=5, iid=False)\n",
    "gs_clf.fit(X_train, y_train)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIfwqKrx4Iuh"
   },
   "source": [
    "**GridSearchCV Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sb8pvFbI3vRB"
   },
   "source": [
    "| Dataset         | score |\n",
    "|-----------------|-------|\n",
    "| Manual          |83.15% |\n",
    "| Auto chi2       |83.15% |\n",
    "| Auto f-classif  |83.15% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vrSTcO_l2jvz"
   },
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gy7wfa42Ezg"
   },
   "outputs": [],
   "source": [
    "parameters = {'C': [0.1, 1, 10, 100, 1000], \\\n",
    "            'kernel': ['linear', 'rbf', 'poly'], \\\n",
    "            'gamma': [0.1, 1, 10, 100], \\\n",
    "            'degree': [0, 1, 2, 3, 4, 5, 6]}\n",
    "\n",
    "clf = SVC()\n",
    "gs_clf = GridSearchCV(clf, parameters, cv=5, iid=False)\n",
    "gs_clf.fit(X_train, y_train)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SdmOk-v84JPQ"
   },
   "source": [
    "**GridSearchCV Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsvhcq_G3v0p"
   },
   "source": [
    "| Dataset         | C           | kernel  | gamma     | degree | score |\n",
    "|-----------------|-------------|---------|-----------|--------|-------|\n",
    "| Manual          |   1         |  poly   |   1       |    3   | 92.46%|\n",
    "| Auto chi2       |   1         |  poly   |   1       |    3   | 92.46%|\n",
    "| Auto f-classif  |   1         |  poly   |   1       |    3   | 92.46%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56SeVuvv2kQU"
   },
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blUEA9cH2Evy"
   },
   "outputs": [],
   "source": [
    "parameters = {'criterion': ['gini', 'entropy'], \\\n",
    "            'splitter': ['best', 'random'], \\\n",
    "            'max_depth': range(1,10)}\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "gs_clf = GridSearchCV(clf, parameters, cv=5, iid=False)\n",
    "gs_clf.fit(X_train, y_train)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQ8vikW54JiA"
   },
   "source": [
    "**GridSearchCV Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMftpll83wfA"
   },
   "source": [
    "| Dataset         | criterion   | splitter| max_depth | score |\n",
    "|-----------------|-------------|---------|-----------|-------|\n",
    "| Manual          |   gini      |  best   |      9    | 83.78%|\n",
    "| Auto chi2       |   gini      |  best   |      7    | 83.68%|\n",
    "| Auto f-classif  |   gini      |  best   |      8    | 83.78%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xfVkbepA2ko7"
   },
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbEbx-r62_8C"
   },
   "outputs": [],
   "source": [
    "parameters = {'criterion': ['gini', 'entropy'], \\\n",
    "            'n_estimators': [1, 10, 100, 200, 300], \\\n",
    "            'max_depth': range(1,10)}\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "gs_clf = GridSearchCV(clf, parameters, cv=5, iid=False)\n",
    "gs_clf.fit(X_train, y_train)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VsRI3Efs4Jyd"
   },
   "source": [
    "**GridSearchCV Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHhgRCIO3w-n"
   },
   "source": [
    "| Dataset         | criterion   | n_estimators | max_depth | score |\n",
    "|-----------------|-------------|--------------|-----------|-------|\n",
    "| Manual          |  entropy    |   200        |      9    | 90.10%|\n",
    "| Auto chi2       |  entropy    |   200        |      9    | 90.39%|\n",
    "| Auto f-classif  |  entropy    |   200        |      9    | 90.16%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i--Xe6jL9al8"
   },
   "source": [
    "## Best classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l55xhULfAilt"
   },
   "source": [
    "From our experiments, we determined that the best classifier based on image features is SVC (Support Vector Machines). It scored 92.46% percent accuracy through all datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIZpWBMJ2Esl"
   },
   "outputs": [],
   "source": [
    "# selecting best clasifier\n",
    "best_clf = SVC(C=1, cache_size=200, class_weight=None, coef0=0.0, \\\n",
    "                    decision_function_shape='ovr', degree=3, gamma=1, kernel='poly', \\\n",
    "                    max_iter=-1, probability=False, random_state=None, shrinking=True, \\\n",
    "                    tol=0.001, verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "apvVXA9Q3UMx"
   },
   "source": [
    "## Bonus classifier experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wf20BauJ3Lgd"
   },
   "outputs": [],
   "source": [
    "# Training and scoring Ada Boost Classifier algorithm\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_k_train, X_k_test = X_train[train_index], X_train[test_index]\n",
    "    y_k_train, y_k_test = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    clf = AdaBoostClassifier(base_estimator=best_clf, random_state = 20, algorithm='SAMME')\n",
    "    clf.fit(X_k_train, y_k_train)\n",
    "    print(clf.score(X_k_test, y_k_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "naASgGW69qY3"
   },
   "source": [
    "| Dataset         | run 1   | run 2  | run 3  |\n",
    "|-----------------|---------|--------|--------|\n",
    "| Manual          | 68.75%  | 69.44% | 71.47% |\n",
    "| Auto chi2       | 66.49%  | 63.02% | 70.26% |\n",
    "| Auto f-classif  | 69.96%  | 73.09% | 72%    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jvrR--9R2EpZ"
   },
   "outputs": [],
   "source": [
    "# Training and scoring Quadratic Discriminant Analysis algorithm\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_k_train, X_k_test = X_train[train_index], X_train[test_index]\n",
    "    y_k_train, y_k_test = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    clf = QuadraticDiscriminantAnalysis()\n",
    "    clf.fit(X_k_train, y_k_train)\n",
    "    print(clf.score(X_k_test, y_k_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "75fOAPOq9qzO"
   },
   "source": [
    "| Dataset         | run 1   | run 2  | run 3  |\n",
    "|-----------------|---------|--------|--------|\n",
    "| Manual          | 80.38%  | 85.93% | 81.04% |\n",
    "| Auto chi2       | 87.67%  | 80.20% | 80.52% |\n",
    "| Auto f-classif  | 78.99%  | 77.08% | 84.52% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sl1L_Mnv3adb"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vW6TmT4wBMFu"
   },
   "source": [
    "Different feature selection methods appeared not to have any meaningful effect on classification scoring. Most of the scores of the same algorithm with different datasets were the same. The exception was RandomForestClassifier where results were between 90.10% and 90.39%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wd4DrQNOCNr6"
   },
   "source": [
    "We haven't anticipated this result beforehand. we hypothesized that different feature selection methods would yield different classification results. We didn't see that. On further investigation, we suspect that either we selected the same features manually as automatic algorithms or that there are too few features to differentiate between different selection methods. Experiments with different feature numbers in automatic feature selection might yield different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVgbU_l4vPwh"
   },
   "source": [
    "Out of our five tested classifiers consistently the best was SVC (Support Vector Machines). It scored over 92% with all datasets. All classifier list from best to last :\n",
    "1. SVC - 92.46%\n",
    "2. RandomForestClassifier - 90.39%\n",
    "3. KNeighborsClassifier - 88.41%\n",
    "4. DecisionTreeClassifier - 83.78%\n",
    "5. Gaussian naive bias - 83.15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1586559141154,
     "user": {
      "displayName": "Dovydas Valiulis",
      "photoUrl": "",
      "userId": "15268906399653486759"
     },
     "user_tz": -120
    },
    "id": "plJmbSE1AVqJ",
    "outputId": "0bcf0aff-d031-4801-f0ff-17876afa5ffa"
   },
   "outputs": [],
   "source": [
    "# Validating best clasifier\n",
    "best_clf.fit(X_train, y_train)\n",
    "score = best_clf.score(X_validate, y_validate)\n",
    "print(\"validation score: {}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2r3hnVEDkUZ"
   },
   "source": [
    "Our best classification algorithm yielded validation score of : 96.88%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1586559143807,
     "user": {
      "displayName": "Dovydas Valiulis",
      "photoUrl": "",
      "userId": "15268906399653486759"
     },
     "user_tz": -120
    },
    "id": "P-wkEIdZSvVu",
    "outputId": "a34e0b11-4deb-420e-9ded-4865c3aa703d"
   },
   "outputs": [],
   "source": [
    "predicted = best_clf.predict(X_validate)\n",
    "print(classification_report(y_validate, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1169,
     "status": "ok",
     "timestamp": 1586559666315,
     "user": {
      "displayName": "Dovydas Valiulis",
      "photoUrl": "",
      "userId": "15268906399653486759"
     },
     "user_tz": -120
    },
    "id": "gRgik32oS1rJ",
    "outputId": "a486cd8a-9dea-4c2b-fcdc-b9ececd1b4b3"
   },
   "outputs": [],
   "source": [
    "cf = confusion_matrix(y_validate, predicted)\n",
    "\n",
    "df_cm = pd.DataFrame(cf, index = [i for i in \"0123456789\"],\n",
    "                  columns = [i for i in \"0123456789\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "ax = sn.heatmap(df_cm, annot=True)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wjOfn8wnVNHR"
   },
   "source": [
    "From the confusion matrix, we can see that six out of ten numbers are classified with a 100% accuracy. In this plot, we can see that the most difficult numbers to classify for this solution are 0, 4, 5, 9. All these numbers share some features of each other. For instance, 4 and 9 have one hole and have a trail in the bottom part of the number. From the Confusion matrix, we also can see that 9 was the hardest number to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Image classifier artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(X,'../dataset-numpy/img-f-dataset.pkl')\n",
    "dump(labels,'../dataset-numpy/img-f-dataset-labels.pkl')\n",
    "\n",
    "bst_sclr = load(TEMP_DIR_PATH + '/preprocessors/manual-image-feature-preprocessor.pkl')\n",
    "dump(bst_sclr,'../classifiers/best-img-f-sclr.pkl')\n",
    "\n",
    "dump(best_clf,'../classifiers/best-img-f-clf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RoB1MOJvWm56"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "82GvxQeBWpv0"
   },
   "source": [
    "Having done experiments on both image-based and grid-based feature classification we can definitively say that grid-based feature classification is better by around 2% when comparing the best image feature classifier and grid feature classifier. Furthermore, when determining the whole zip code difference of 2 percent in single-digit recognition is exponentially higher. Therefore, a better solution for zip code prediction is grid-based feature classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-IgLHzE85no"
   },
   "source": [
    "# Cleanup\n",
    "Ensure no data is left on the runtime after execution of all code has completed. This ensures we won't re-use old data once something in the code has changed, eliminating the risk of hours of debugging functional code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1586555267606,
     "user": {
      "displayName": "Dovydas Valiulis",
      "photoUrl": "",
      "userId": "15268906399653486759"
     },
     "user_tz": -120
    },
    "id": "1b3XVy4t8Ey0",
    "outputId": "edc4a556-569a-46ff-ce75-036acf0a08f9"
   },
   "outputs": [],
   "source": [
    "# # Remove all data from the /content directory\n",
    "# if os.path.isdir(DATASET_IMAGES_PATH):\n",
    "#   shutil.rmtree(DATASET_IMAGES_PATH)\n",
    "\n",
    "# if os.path.isfile(DATASET_CSV_PATH):\n",
    "#   os.remove(DATASET_CSV_PATH)\n",
    "\n",
    "# if os.path.isfile(KNN_CLASSIFIER_PATH):\n",
    "#   os.remove(KNN_CLASSIFIER_PATH)\n",
    "\n",
    "# if os.path.isfile(SCALER_PATH):\n",
    "#   os.remove(SCALER_PATH)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "iJQxTLQ4tf6E"
   ],
   "name": "Training / Testing / Validation",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
